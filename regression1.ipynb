{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In multiple linear regression we have **many** independent variables and only **one** dependent vatiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Assumptions of a linear regression models -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each LR(linear regression) model has some set of assumptions. The major of them are:\n",
    ">    1. linearity,\n",
    ">    2. honoscedosticity,\n",
    ">    3. multivatient normality,\n",
    ">    4. independance of errors, and\n",
    ">    5. lack of multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dummy variables -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy variables are one way to handel categorical value. The idea is to create different features derived from the different categories. Example:\n",
    "> colors: {red, blue, green, red, green}\n",
    "\n",
    "Here the three categories are {red, blue, green}. The three different columns are created what will hold boolean values. If the i<sup>th</sup> was red then only the _red_ column will have 1 in it and all other zeros. This is repeated for every training example.\n",
    "\n",
    "This is a great way to handel categorical values, but it can lead to some problems. The major one is the _multi-collinearity_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. P value -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every event has some probabiity associated to it. As an example tossing a coin has 50/50 probability of giving heads and tails.\n",
    "\n",
    "But how can the \"_fairness_\" of the coin be juged? How can it be juged that the coin is _fair_? This is were _hypotesis testing_ comes is.\n",
    "\n",
    "The coin can be a fair coin or an unfair coin. Then an assumption is made about the _state_ of the coin and by tossing it the assumption is tested. It the coin is fair we expect a mix of heads and tail. But it we to see the same outcome again and again it seems to get <u>sus</u>.\n",
    "\n",
    "That sus feeling, the point at which it feels that maybe the initial hypothesis, called the \"_null hypothesis_\" was incorrect is called the _**P**_ value of the hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. How to build a model? -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset -->\n",
    "raw_data = pd.read_csv(\"data/50_Startups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data description -->\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the train-test split -->\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(raw_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pipelines and column transformers to pre-process data -->\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xy(dataset: pd.DataFrame, target: str) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    # split the data in X and y\n",
    "    X = dataset.drop(target, axis=1)\n",
    "    y = dataset[target].copy()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nums_cats(X: pd.DataFrame, cat_vars: list) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    X_nums = X.select_dtypes([np.number])\n",
    "    X_cats = X[cat_vars]\n",
    "\n",
    "    return X_nums, X_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_xy(train_data, \"Profit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, X_train_cat= get_nums_cats(X_train, [\"State\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the column transformer -->\n",
    "num_cols = X_train_num.columns\n",
    "cat_cols = X_train_cat.columns\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"std_scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "X_train_num_pl = num_pipeline.fit_transform(X_train_num)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"cat\", OneHotEncoder(), cat_cols)\n",
    "])\n",
    "\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
